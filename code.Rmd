---
title: "PAC 2 Regresión Lineal"
author: "Maria Lucas"
date: "2023-06-22"
output: 
  word_document:
    toc: true
    toc_depth: 4
lang: Es-es
---
\newpage

# Ejercicio 1

```{r}
# Set the file path
file_path <- "D:/Antiguos estudios/MASTER2/Sem2/Regresion/PAC2/P2/pancreas_biomarkers.txt"

# Load the data into a data frame
data <- read.table(file_path, header = TRUE, sep = "\t")

# Display the first few rows of the data frame
head(data)

# Saving variables as factors
data$diagnosis <- factor(data$diagnosis, levels = 1:3)
data$age_cat <- factor(data$age_cat)
```

### (a) Modelo de regresión logística

#### Diagnóstico de todos los casos
```{r}
model <- glm(diagnosis ~ age_cat + creatinine + LYVE1 + REG1B + TFF1, data = data, family = binomial)

summary(model)
```

Tal y como podemos ver en los resultados, tan solo la creatinina, la LYVE1 y el TFF1 son variables que permiten predecir el riesgo de adenocarcinoma ductal pancreático. Se puede observar porque en todas ellas el pvalor es menos a 0.01. En el contexto de regresión logística un pvalor de 0.01 permite rechazar la hipótesis nula de no relación entre la variable predictora y la variable respuesta. En otras palabras, la variable tiene un impacto significativo sobre la clase.

#### Sólo adenocarcinoma y otro

```{r}
# Subset the data to include only levels 2 and 3 of the "diagnosis" variable
subset_data <- subset(data, diagnosis != 1)

# Recode values 2 and 3 to 0 and 1, respectively
subset_data$diagnosis <- ifelse(subset_data$diagnosis == 2, 0, 1)

# Fit the logistic regression model using the subsetted data
model <- glm(diagnosis ~ age_cat + creatinine + LYVE1 + REG1B + TFF1, data = subset_data, family = binomial)

# View the model summary
summary(model)
```

Tal y como podemos ver en los resultados, la edad a partir de 56 años es un indicador significativo. La LYVE1 y el REG1B también son variables que permiten predecir el riesgo de adenocarcinoma ductal pancreático. Se puede observar porque en todas ellas el pvalor es menos a 0.05. En el contexto de regresión logística un pvalor de 0.01 permite rechazar la hipótesis nula de no relación entre la variable predictora y la variable respuesta. En otras palabras, la variable tiene un impacto significativo sobre la clase.

Que el intercepto también sea significativo sugiere que parte de la variable respuesta no es explicada por las variables independientes estudiadas. En regresión logística el intercepto captura la probabilidad de ocurrencia de un suceso cuando todas las variables predictoras están en su nivel de referencia. En otras palabras, un intercepto significativo implica que aunque no tengamos ningun predictor, hay diferencias significativas entre las clases.

### (b) Interpretación de coeficientes

Los coeficientes en un modelo de regresión logística indican el cambio estimado en el log-odds del evento ocurriendo (codeado como 1 = adenocarcinoma ductal pancreático) asociado a una unidad de cambio en la variable predictora, sin variar el resto de variables.

Un estimador positivo sugiere que el incremento de la variable está asociado a un incremento de la probabilidad (log-odds) del evento ocurriendo. Si el estimador es 0.5 significa que al aumentar en 1 el valor del predictor, esto se asopcia a un 0.5 aumento del log-odds del evento ocurriendo. Este es el caso del LYVE1, al aumentar LYVE1 es más probable tener adenocarcinoma (3.140e-01 = 0.3140). Lo mismo sucede con la edad, parece ser que tener más de 56 años aumenta el log-odds de tener adenocacinoma. Lo hace de forma distinta dependiendo del rango de edad, de 56-65 (3.032e+00 = 3.032), de 66-75 (2.700e+00 = 2.700) y a partir de 75 años (3.443e+00 = 3.443).

Contrariamente, un estimador negativo significa que un aumento de la variable disminuye el log-odds del evento ocurriendo (tener adenocarcinoma).

### (c) Modelo reducido

Para comparar ambos modelos podemos realizar un anova aplicando el test Chi cuadrado. Con esto estamos comparando el ajuste del modelo bajo las siguientes hipótesis:

- **H0:** Desviación del modelo reducido = Desviación del modelo completo. No hay diferencia de ajuste entre los modelos.
- **H1:** Desviación del modelo reducido > Desviación del modelo completo. El modelo reducido se ajusta peor que el modelo completo.

La desviación del modelo se refiere a la diferencia entre los valores reales de los datos y los valores predichos por el modelo.

```{r}
# Fit the logistic regression model using the subsetted data
model_simple <- glm(diagnosis ~ age_cat + LYVE1 + REG1B, data = subset_data, family = binomial)

summary(model_simple)

# Compare the two models
anova(model, model_simple, test = "Chi")

# Install and load the "lmtest" package
# install.packages("lmtest")
library(lmtest)

# Perform the likelihood ratio test
lrtest(model, model_simple)

```

Dado que el pvalor no es significativo (0.31) aceptamos la hipótesis nula, el modelo reducido (sin creatinina y sin TFF1) es igual de bueno que el complejo. Adicionalmente, vemos que el AIC del modelo reducido es 2 unidades menor que el del modelo complejo, esto sugiere que el modelo reducido tiene un ajuste mejor teniendo en cuenta la complejidad de ambos modelos.

### (d) Funcion cuadrática

```{r}
# Cuadratic LYVE1
model_simple_LYVE1 = glm(diagnosis ~ age_cat + LYVE1 + I(LYVE1^2) + REG1B, data = subset_data, family = binomial)

summary(model_simple_LYVE1)

# Compare the two models
anova(model_simple, model_simple_LYVE1, test = "Chi")

# Cuadratic REG1B
model_simple_REG1B = glm(diagnosis ~ age_cat + LYVE1 + REG1B + I(REG1B^2), data = subset_data, family = binomial)

summary(model_simple_REG1B)

# Compare the two models
anova(model_simple, model_simple_REG1B, test = "Chi")

```

En ninguno de los dos casos añadir el término cuadrático ha mejorado el ajuste del modelo. Siguiendo la explicación del apartado anterior: pv = 0.3 y 0.4, aceptamos H0 los dos modelos tienen el mismo ajuste.

Adicionalmente, si examinamos el AIC veremos que en los modelos con el término cuadrático este es superior. Un valor mayor AIC sugiere que el modelo no se ajusta mejor para la complejidad que presenta.

En conclusión, no deberíamos incluir ninguno de los dos términos cuadráticos. Es importante comentar que, aunque estos tests aparezcan no-significativos, hay que valorarlos siempre junto con el contexto del análisis. En este caso, se ha realizado adicionalmente una inspección visual de la variable vs el log odds de la variable respuesta (disponible en el ANEXO). Estos gráficos nos confirman que efectivamente, existe una relación lineal, dado que se observa un patrón lineal sin observar otros patrones como curvas, forma de U, etc.

```{r}
# Obtain predicted log odds from the model
predicted_logodds <- predict(model_simple, type = "link")

plot(subset_data$LYVE1, predicted_logodds, xlab = "age_cat", ylab = "Log Odds", main = "Scatter plot - LYVE1 vs. Log Odds")

plot(subset_data$REG1B, predicted_logodds, xlab = "age_cat", ylab = "Log Odds", main = "Scatter plot - REG1B vs. Log Odds")
```

### (e) Predicción de caso

```{r}
# Create a new data frame for the new case
new_case = data.frame(age_cat = "66-75", LYVE1 = 6, REG1B = 140)

# Predict the outcome using the model
prediction = predict(model_simple, newdata = new_case, type = "response")

print(prediction)
```
El modelo predice la presencia de adenocarcinoma ductal pancreático con un 72,42% de probabilidad. Recordemos que los valores fueron recodificados a 0 = afecciones pancreáticas no cancerosas y 1 = adenocarcinoma ductal pancreático.

La extrapolación ocurre cuando se hacen predicciones de para datos de la variable predictora fuera del rango de los datos usados para contruir el modelo.

```{r}
# Check predictor variable ranges
range_data <- sapply(subset_data[, c("LYVE1", "REG1B")], range)
range_new_observation <- c(6, 140)  # Replace with the values of the new observation

# Compare new observation values with observed range
is_extrapolation <- any(range_new_observation < range_data[1, ] | range_new_observation > range_data[2, ])

# Print results
cat("Extrapolation:", is_extrapolation, "\n")

# Assess distribution of predictor variables
# LYVE1
hist(subset_data$LYVE1, main = "Distribution of LYVE1")
# Add new observation to LYVE1 plot
points(6, 0, col = "red", pch = 16)

# REGB1
hist(subset_data$REG1B, main = "Distribution of REG1B")
# Add new observation to REGB1 plot
points(140, 0, col = "red", pch = 16)

# age_cat
barplot(table(subset_data$age_cat), main = "Distribution of age_cat", xlab = "age_cat", ylab = "Frequency")
# Add new observation to age_cat plot
points(5.5, 0, col = "red", pch = 16)
```

Como podemos ver, los valores del caso a predecir se encuentra entre el rango utilizado para construir el modelo.

# Ejercicio 2

```{r}
set.seed(123)

# Data import
# Note: I changed the variable names to avoid problems

import.data <-
"http://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/telemonitoring/parkinsons_updrs.data"
parkinson <- read.table(url(import.data), sep=",", skip=1)
names(parkinson) <- c("subject#","age","sex","test_time","motor_UPDRS","total_UPDRS",
"Jitter_p","Jitter_Abs","Jitter_RAP","Jitter_PPQ5","Jitter_DDP",
"Shimmer","Shimmer_dB","Shimmer_APQ3","Shimmer_APQ5","Shimmer_APQ11", "Shimmer_DDA","NHR","HNR","RPDE","DFA","PPE")

# install.packages('caTools')
library(caTools)

# Split the data into training and testing sets
split = sample.split(parkinson, SplitRatio = 0.8)
train_data = parkinson[split, ]
test_data = parkinson[!split, ]
```

### (a) Regresión lineal

Al no utilizar el factor "sujeto" no tenemos en cuenta las posibles variaciones de cada individuo. Las muestras deberían ser apareadas, ya que se ace un seguimiento a lo largo del tiempo. Una estimación. No sé lo que digo ya lo mirare.

```{r}
# Fit the model
model_lineal = lm(total_UPDRS ~ Jitter_p + Jitter_Abs + Jitter_RAP + Jitter_PPQ5 + Jitter_DDP + Shimmer + Shimmer_dB + Shimmer_APQ3 + Shimmer_APQ5 + Shimmer_APQ11 + Shimmer_DDA + NHR + HNR + RPDE + DFA + PPE, data = train_data)

# Extract R-squared
r_squared = summary(model_lineal)$r.squared

# Extract adjusted R-squared
adj_r_squared = summary(model_lineal)$adj.r.squared

# Predict on the training data
predictions_train = predict(model_lineal, train_data)

# Calculate residuals
residuals_train = train_data$total_UPDRS - predictions_train

# Calculate RMSE
rmse_train = sqrt(mean(residuals_train^2))

# Predict on the test data
predictions_test <- predict(model_lineal, test_data)

# Calculate residuals
residuals_test <- test_data$total_UPDRS - predictions_test

# Calculate RMSE
rmse_test <- sqrt(mean(residuals_test^2))

# Extract the variable names from the linear regression model
variables <- names(coef(model_lineal))[-1]

# Create a data frame for the results
results_table <- data.frame(
  Metric = c("Número de variables", "R-squared", "Adjusted R-squared", "RMSE_train", "RMSE_test"),
  Value = c(length(variables), r_squared, adj_r_squared, rmse_train, rmse_test)
)

# Print the result table
print(results_table)
cat("Variables usadas en el modelo: ")
cat(variables, sep=", ")

```

Al no considerar el "sujeto" se viola la suposición de independencia. En este tipo de modelos, se asume que todas las observaciones son independientes. Al no serlo, se construirá un modelo que incluirá métricas erróneas. De manera similar, se pierde precisión al no tener en cuenta la correlación entre los datos. El error estándar de los coeficientes estimados puede subestimarse, dando intervalos de confianza más estrechos.

Adicionalmente, se aumenta el error de Tipo 1 (rechazar incorrectamente H0 haciendo que una variable sea significativa cuando no lo es). Esto sucede porque los datos de un mismo individuo tienden a ser más similares, inflando así la significación de los resultados. 

Finalmente, se hace más complicado detectar las variaciones entre en un mismo individuo. 

### (b) Regresión lineal con AIC

```{r}
library(MASS)

# Perform stepwise variable selection based on AIC
model_stepwise <- stepAIC(model_lineal, direction = "both", trace = FALSE)

# Extract R-squared
r_squared = summary(model_stepwise)$r.squared

# Extract adjusted R-squared
adj_r_squared = summary(model_stepwise)$adj.r.squared

# Predict on the training data
predictions_train = predict(model_stepwise, train_data)

# Calculate residuals
residuals_train = train_data$total_UPDRS - predictions_train

# Calculate RMSE
rmse_train = sqrt(mean(residuals_train^2))

# Predict on the test data
predictions_test <- predict(model_stepwise, test_data)

# Calculate residuals
residuals_test <- test_data$total_UPDRS - predictions_test

# Calculate RMSE
rmse_test <- sqrt(mean(residuals_test^2))

# Extract the variable names from the linear regression model
variables <- names(coef(model_stepwise))[-1]

# Create a data frame for the results
results_table <- data.frame(
  Metric = c("Número de variables", "R-squared", "Adjusted R-squared", "RMSE_train", "RMSE_test"),
  Value = c(length(variables), r_squared, adj_r_squared, rmse_train, rmse_test)
)

# Print the result table
print(results_table)
cat("Variables usadas en el modelo: ")
cat(variables, sep=", ")
```

### (c) Regresión por componentes principales



### (d) Ridge regression

### (e) motor_UPDRS como respuesta

### (f) Análisis de residuos

# Ejercicio 3

### (a) Comparación modelos con y sin puntos influyentes

### (b) Cálculo del RMSE robusto

### (c) LTS o Huber

# ANEXO

### Código